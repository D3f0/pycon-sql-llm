---
title: "Asking questions to your database with LLMs"
subtitle: "Techniques for effective SQL generation"
# Add IBM logo
author: Nahuel Defoss√© <br>[nahuel.defosse@ibm.com](mailto:nahuel.defosse@ibm.com)<br>IBM Research Kenya Lab
date: September, 2025
embed-resources: true
format:
  revealjs:
    theme: dark
    toc: true
    toc-depth: 1
    slide-number: true
    transition: slide
    code-copy: true
    highlight-style: github
    revelaljs:
      include-in-header: 
        text: |
          <style>
          .center-xy, .center-xy *{
            margin: 0;
            position: absolute;
            top: 50%;
            left: 50%;
            -ms-transform: translateY(-50%), translateX(-50%);
            transform: translateY(-50%), translateX(-50%);
          }
          </style>

---


## About myself

::: {.columns}
::: {.column width="40%"}
![](./img/myself.jpg){.center-xy}
:::

::: {.column width="60%"}

::: {.incremental}
- Worked in Agritech at Hello Tractor
- Software Engineer at IBM Research  Nairobi
- Worked in Foundational Models for Geospatial applications üõ∞Ô∏èüó∫Ô∏èü§ñ
- Currently working on Flowpilot project, providing core features to 
  different products and divisions.
:::

:::
:::


---

## LLMs used for SQL generation

LLMs have been  capable of generating SQL from text questions for some time.
Models have been trained with large sets of queries enabling the generation of complex joins expressions, window functions with custom aggregation as well as breaking
down the problem into pieces using common table expressions.

---

## What is our goal

::: {.incremental}
- Develop and test new and existing SoTA techinques against public and proprietary datasets
  - Benchmarking (e.g. [unitxt](https://github.com/IBM/unitxt))
- Support multiple dialects (CSV, SQLite, Postgres, Presto, db2) 
- Multi tenancy in internal SaaS.
- Augmented **chat** interaction as well ass **api** access (both as SaaS ‚òÅÔ∏è and on-prem üè¢ deployments)
- Enable tool calling for *agentic* use cases
- Extensibility and auto-configuration based on benchmarks.
:::

---

## Where to start

### Spider dataset

![](./img/spider-1.png)

::: footer 
166 SQLite databases, code repository and public leaderboard.
:::

---
### Example of a SQLite DB in spider

![](./img/spider-1-sample.png)


---

### Example of the queries {.scrollable}

:::: {.columns}
::: {.column with="50%"}
![](./img/spider_examples_easy_med.png)
:::
::: {.column with="50%" height="100%"}

![](./img/spider_examples.png)
:::

::::

---

### Spider leaderboard


<div style="height: 80%">
![](./img/leaderboard-bird1.png)
</div>

::: footer
#TODO put IBM
:::
---

### Spider 2

![](./img/spider.png)

Comes in 3 flavours

:::: {.columns}

::: {.column width="33%"}
Snowflake
::: 

::: {.column width="33%"}
SQLite
::: 

::: {.column width="33%"}
`dbt` (data build toolkit)
::: 

::::
---

### Spider 2 

![](./img/Spider2-structure.png)

---

### Spider 2

This focuses on larger datasets, in many cases, analytic databases.

:::: {.columns}


::: {.column with="50%"}
TBD
:::
::: {.column with="50%"}
TBD
:::

::::


---

### BIRD

![](./img/bird.png){.center-xy} 

::: footer

:::

---

## Relevant challenges

::: {.incremental}
- üí¨ Chat interfaces are good for question input
- üßëüèΩ‚Äçüè´ ... not very convenient to provide samples (sql tends to be long)
- Generally we need to provide the DDL (strucutre) if it fits
- ü•¥ Models can hallucinate making up inexistent tables, columns or functions
- SQL dialects have their nuances (SQLite, Postgres, MySQL)
:::


---

## Providing context

### Schema linking

SL is an common improvement over prompt engineering to improve the of the generated SQL, which consists on mapping words to tables, columns and values.

---

### Schema Liking Techniques

::: {.incremental}
- Prompt engineering
  - Providing `CREATE TABLE customers (name varchar...)`
- Retrieval Augmented Generation RAG
- Agentic approaches, function calling
  - `give_me_tables(user_input)`
- Fine tuned models
  - Provide SQL examples and their meaning
:::

---

-

---

## Fixing errors

---

## Current OSS tooling

- ü¶ú ‚õìÔ∏è LangChain: [`Q/A over SQL data`](https://python.langchain.com/docs/tutorials/sql_qa/)

::: fragment
```{python}
print(1)

```
::: 
---

## Pydantic AI 

2- PyDantic's AI [`SQL workbench`](https://ai.pydantic.dev/examples/sql-gen/)

---

## Common challenges

- Some databases have specific dialects, e.g. SQLite, Postgres, MySQL, Oracle, db2, etc.
- The training set of the models may not have a sufficient examples 
  for the database engine we're interested in.
- Providing tables is great, but some times, schemas are quite big
  and the table and column names may be not human friendly.


---

## Pipelines

Our work was focused on prompt optimization by a small team, but as 
our teams tarted to grown we needed to allow different research team
to focus on different areas.

We created a framework inspired in LangGraph tailored to the text2sql 
generation. 


```mermaid
graph DR
  A -> B
````

## Engineering Challenges

Some

- Bird benchmarks
- Benchmarks frameworks
	- Unitxt
- Pipelines
- 
- Providing context 
	- 
- Shape of the context 
- Model sizes
	- Limits
- other node

---
