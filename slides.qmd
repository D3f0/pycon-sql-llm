---
title: "üí¨ ‚ùì ü§ñ Asking questions to your database with LLMs "
# subtitle: "Techniques for effective SQL generation"
author: Nahuel Defoss√© <br>[nahuel.defosse@ibm.com](mailto:nahuel.defosse@ibm.com)<br>IBM Research Kenya Lab
date: September, 2025
embed-resources: false
# https://quarto.org/docs/computations/caching.html
execute: 
  cache: true
  keep-ipynb: true
format:
  revealjs:
    toc: true
    toc-depth: 1
    slide-number: true
    transition: slide
    code-copy: true
    highlight-style: github
    theme: [solarized, custom.scss]  
  
notes: >
  This talk will cover a research project within IBM Research focused on generating structured 
  query language queries for your data using open-source models based on the work of the 
  Nairobi and Johannesbug Research labs.

  We will cover the state of the art in terms of techniques to augment the prompt in terms of 
  database structure and contents to help build more specific queries, error correction, 
  prompt reformulation, and other approaches. We will briefly discuss how 
  fine-tuning of models can help in some scenarios.

  We will close this talk by discussing the tools used for building this kind 
  of project and some of the lessons learned along the way.

todo: >
  https://research.ibm.com/projects/flowpilot
  Add https://www.youtube.com/watch?v=bEgnVKb_J4k

---

# About myself {.smaller}

:::: {.columns}
::: {.column width="40%"}
![](./img/memes/myself.gif){height="12em"}
:::

::: {.column width="60%"}

::: {.incremental}
- üêç Pythonista with 18 years of experience.
  - Co-organized SciPy Latin America
- üöú Worked as CTO in  Hello Tractor 
- üß™ Software Engineer at IBM Research 
- üõ∞Ô∏è Worked in Foundational Models for Geospatial applications
- üí¨ Currently working on [Flowpilot {{< bi link-45deg >}}](https://research.ibm.com/projects/flowpilot), providing core features to 
  different products and divisions.
::: 

:::
::::


---

# Getting started

---

## About LLMs

LLMs are quite capable of writing functional SQL queries.

. . . 

For those of us who have been writing code for some time and 
fell in love with ORMs when they were the *hot* new thing, LLMs
can take us to the next level!

. . . 

But they don't know the üèóÔ∏è structure of our database, and may hallucinate 
about it, or create some flat out invalid SQL, so we will need to handle
some of this scenarios.

::: notes
In Flowpilot we created a framework inspired on LangGraph for this.
:::

---

## Before we start, Which LLMs should we use
::: {.fragment .fade-in-then-out}
There are some reasonably good LLMs under the coder and instruct in Hugging Face.
Some of these can be run locally with some inference server like `Ollama`, 
`llama.cpp` or `LMStudio`, and also use pubic 
ones.
:::

::: {.fragment .fade-in-then-out}
Running LLMs locally or on-prem scenarios is quite important when
we need to preserve the confidentiality of the data. 
:::

::: {.fragment .fade-in-then-out}
We'll take a look at a library/proxy that can help us move between LLMs
called `litellm` (can also add observability, cost tracking, etc.).
:::

---

### Contacting LLMs with `littellm` SDK

::: {.fragment .fade-in-then-out}
`uv add littellm` and, for local execution, we can also add ollama Python package `uv add ollama`.

:::

::: {.fragment .fade-in-then-out}
`litellm` uses a prefix for the provider of the LLM (it supports 100+ providers)

For `ollama`, we will check if it's running as a service (if not check the docs, its OS specific)
:::

::: {.fragment}
Is ü¶ô running?
```{python}
#| echo: true 

import socket; s = socket.socket(); s.settimeout(.5); s.connect_ex(('localhost', 11434)) == 0
```
:::

---

### Getting some completions {.center}

```{python}
#| echo: true
#| output: true
#| code-overflow: wrap
import ollama
print("Models:", *(f"ollama/{m.model}" for m in ollama.list()["models"]), sep="\n")
from litellm import completion
```

---

### Getting some completions (cont.) {.center}
```{python}
#| echo: true
#| output: true
#| 
from litellm import completion

messages = [
  {"role": "user", 
  "content": "Create a small customer table in SQL"}]
response = completion(
  model="ollama/hf.co/unsloth/DeepSeek-R1-Distill-Llama-8B-GGUF:F16", 
  messages=messages, stream=False
)
print(response['choices'][0]['message']['content'])
```

---

<!-- ### More tools ‚öíÔ∏è for dealing with SQL {background-image="./img/memes/old-man-giving-link-a-sword-in-the-legend-of-zelda.jpg"} -->
### More tools ‚öíÔ∏è for dealing with SQL {background-image="https://static0.thegamerimages.com/wordpress/wp-content/uploads/2023/04/old-man-giving-link-a-sword-in-the-legend-of-zelda.jpg?q=50&fit=crop&w=1100&h=618&dpr=1.5"}

::: {.columns .small_text}
::: {.column }
#### LangGraph

Allows us to create code **Workflows** with nodes and edges.
Nodes can be function or classes.
:::

::: {.column}
#### Pydantic

**Data validation** library, allows to convert JSON into
Python objects easily and has very good performance given
that it's been re-written in Rust ü¶Ä
:::

:::


::: {.columns .small_text}
::: {.column }
#### SQLGlot

A sql **parser** and transpiler. Generates an AST for multiple 
[31+ database engines](https://sqlglot.com/sqlglot/dialects.html) that can be converted from one format to another.
:::

::: {.column}
#### SQLAlchemy

Can connect to multiple databases and execute queries. 
Has a great inspection API which can give us back
the structure of the DB.
:::

:::

---

## Let's go for Bobby tables {.center}

![](./img/memes/exploits_of_a_mom.png)

::: footer
[`xkcd 327`](https://www.explainxkcd.com/wiki/index.php/327:_Exploits_of_a_Mom)
::: 

---

## Let's grab some {{< bi database >}} from üê¶ benchmark

::: {.smaller}
```{python}
#| echo: true
import fsspec, rich
url = "http://bird-bench.oss-cn-beijing.aliyuncs.com/dev.zip"
rfs, *_ = fsspec.mapping.url_to_fs(f"filecache::zip::{url}", mode="r")

inner_zip_path, *_ = rfs.glob('**/dev_databases.zip')
rich.print(inner_zip_path)
#db_zips = rfs.open(inner_zip_path)



```
:::

---
